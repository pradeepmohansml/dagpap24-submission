{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ccf9af37-90b4-4ebb-a0d0-33ec5b216bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81ff53ad-083d-4e33-b5dc-59ad9bb05489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25223ae2-2f61-4161-84c0-d319987bf6ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dagpap24-submission/notebooks\n"
     ]
    }
   ],
   "source": [
    "parent_directory = os.getcwd()\n",
    "print(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972490cb-d3ae-4c65-b31e-99bf028d8c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a02c78-48f6-4efe-a169-eca762879d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contesting_models = ['roberta', 'scibert', 'deberta', 'biomed_roberta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6da1f6-b4fd-4e75-bada-30456f1bd5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ec2-user/SageMaker/dagpap24-submission/notebooks/data/output_dev_roberta', '/home/ec2-user/SageMaker/dagpap24-submission/notebooks/data/output_dev_scibert', '/home/ec2-user/SageMaker/dagpap24-submission/notebooks/data/output_dev_deberta', '/home/ec2-user/SageMaker/dagpap24-submission/notebooks/data/output_dev_biomed_roberta']\n"
     ]
    }
   ],
   "source": [
    "model_path = []\n",
    "for model in contesting_models:\n",
    "    model_path.append(f'{parent_directory}/data/output_dev_{model}')\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aee1fb0-1170-43ae-b0aa-a415fdecf3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cd023-f5ec-46e5-9f54-acaa0b3cfc94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd35be0-428a-461e-aaf9-29482641d78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_roberta = AutoModelForTokenClassification.from_pretrained(model_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7514cd9-a4cd-4b9b-88ac-bbc52a7e05c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_roberta.push_to_hub('TheOptimusPrimes/roberta-finetuned-dagpap24',\n",
    "                          \"Pushing Roberta fine-tuned model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead88ca7-1d5d-4260-92e0-693290d9ac2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "roberta_tokenizer = RobertaTokenizerFast.from_pretrained('FacebookAI/roberta-base',\n",
    "        cache_dir=model_path[0],\n",
    "        use_fast=True,\n",
    "        revision=\"main\",\n",
    "        use_auth_token=None,\n",
    "        add_prefix_space=True,\n",
    "    )\n",
    "roberta_tokenizer.pad_token = roberta_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635991e8-7108-41c7-adb9-18a75069fc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roberta_tokenizer.push_to_hub('TheOptimusPrimes/roberta-finetuned-dagpap24',\n",
    "                          \"Pushing Roberta fast tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58fb053-7314-440c-bad8-d33d0fdb0792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9373726-067d-4795-b17d-77fb9cc6f7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff44eef-3674-4d2d-a39b-51b15e629eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ae84f8-7eaa-435c-9662-98f593a65cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50dc43a-a44c-47f8-b659-51bb4b90dc61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "test_uploaded_tokenizer = AutoTokenizer.from_pretrained(\"TheOptimusPrimes/roberta-finetuned-dagpap24\")\n",
    "test_uploaded_model = AutoModelForTokenClassification.from_pretrained(\"TheOptimusPrimes/roberta-finetuned-dagpap24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85f1c42e-b867-449b-b3a7-ddf3970485a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "        test_uploaded_tokenizer, pad_to_multiple_of=8 if False else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5b1db76-a9e9-45b0-a07c-b376f9323677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d56ce540-3a5d-49fd-96c0-d44e4c5d3110",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"f1\", module_type: \"metric\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n",
       "Args:\n",
       "    predictions (`list` of `int`): Predicted labels.\n",
       "    references (`list` of `int`): Ground truth labels.\n",
       "    labels (`list` of `int`): The set of labels to include when `average` is not set to `'binary'`, and the order of the labels if `average` is `None`. Labels present in the data can be excluded, for example to calculate a multiclass average ignoring a majority negative class. Labels not present in the data will result in 0 components in a macro average. For multilabel targets, labels are column indices. By default, all labels in `predictions` and `references` are used in sorted order. Defaults to None.\n",
       "    pos_label (`int`): The class to be considered the positive class, in the case where `average` is set to `binary`. Defaults to 1.\n",
       "    average (`string`): This parameter is required for multiclass/multilabel targets. If set to `None`, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data. Defaults to `'binary'`.\n",
       "\n",
       "        - 'binary': Only report results for the class specified by `pos_label`. This is applicable only if the classes found in `predictions` and `references` are binary.\n",
       "        - 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
       "        - 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
       "        - 'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters `'macro'` to account for label imbalance. This option can result in an F-score that is not between precision and recall.\n",
       "        - 'samples': Calculate metrics for each instance, and find their average (only meaningful for multilabel classification).\n",
       "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n",
       "\n",
       "Returns:\n",
       "    f1 (`float` or `array` of `float`): F1 score or list of f1 scores, depending on the value passed to `average`. Minimum possible value is 0. Maximum possible value is 1. Higher f1 scores are better.\n",
       "\n",
       "Examples:\n",
       "\n",
       "    Example 1-A simple binary example\n",
       "        >>> f1_metric = evaluate.load(\"f1\")\n",
       "        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0])\n",
       "        >>> print(results)\n",
       "        {'f1': 0.5}\n",
       "\n",
       "    Example 2-The same simple binary example as in Example 1, but with `pos_label` set to `0`.\n",
       "        >>> f1_metric = evaluate.load(\"f1\")\n",
       "        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], pos_label=0)\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.67\n",
       "\n",
       "    Example 3-The same simple binary example as in Example 1, but with `sample_weight` included.\n",
       "        >>> f1_metric = evaluate.load(\"f1\")\n",
       "        >>> results = f1_metric.compute(references=[0, 1, 0, 1, 0], predictions=[0, 0, 1, 1, 0], sample_weight=[0.9, 0.5, 3.9, 1.2, 0.3])\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.35\n",
       "\n",
       "    Example 4-A multiclass example, with different values for the `average` input.\n",
       "        >>> predictions = [0, 2, 1, 0, 0, 1]\n",
       "        >>> references = [0, 1, 2, 0, 1, 2]\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"macro\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.27\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"micro\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.33\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=\"weighted\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.27\n",
       "        >>> results = f1_metric.compute(predictions=predictions, references=references, average=None)\n",
       "        >>> print(results)\n",
       "        {'f1': array([0.8, 0. , 0. ])}\n",
       "\n",
       "    Example 5-A multi-label example\n",
       "        >>> f1_metric = evaluate.load(\"f1\", \"multilabel\")\n",
       "        >>> results = f1_metric.compute(predictions=[[0, 1, 1], [1, 1, 0]], references=[[0, 1, 1], [0, 1, 0]], average=\"macro\")\n",
       "        >>> print(round(results['f1'], 2))\n",
       "        0.67\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load(\"f1\")\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23cea365-1511-44d8-842c-32086f32b450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    merged_predictions = [\n",
    "        label_list[p]\n",
    "        for (p, l) in zip(predictions.flatten(), labels.flatten())\n",
    "        if l != -100\n",
    "    ]\n",
    "    merged_labels = [\n",
    "        label_list[l]\n",
    "        for (p, l) in zip(predictions.flatten(), labels.flatten())\n",
    "        if l != -100\n",
    "    ]\n",
    "    \n",
    "    results = metric.compute(\n",
    "        predictions=merged_predictions,\n",
    "        references=merged_labels,\n",
    "        average=\"macro\",\n",
    "    )\n",
    "\n",
    "    # if data_args.return_entity_level_metrics:\n",
    "    if False:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"f1\": results[\"f1\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42cbe180-7b1b-4c69-a573-b41de2b22933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=test_uploaded_model,\n",
    "        # args=training_args,\n",
    "        # train_dataset=train_dataset if training_args.do_train else None,\n",
    "        # eval_dataset='data/data_gen_content_val_roberta.json',\n",
    "        tokenizer=test_uploaded_tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9e26b91-cc0c-4d06-9706-da1bbbbdfc45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bb327b6cfd47e0b72dd442af70d06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ac8ee2a8be4024b2a55148784cd73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09dcb6fef07942138e73bee38d788531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b218355fd4dd4421a61213a29f703695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "my_datasets = load_dataset('json', data_files={'test': 'data/data_gen_content_dev_roberta.json', \n",
    "                                               'validation': 'data/data_gen_content_val_roberta.json'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9126dd-631a-4b59-9fc2-98d242d72b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "my_datasets = load_dataset('parquet', data_files={'test': 'data/dev_data.parquet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d66923a-426e-49d7-ba59-6642066bc1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'index': Value(dtype='int64', id=None), 'ner_tags': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "features = my_datasets[\"validation\"].features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a40902a-d89f-4fb8-842b-90e6bff1ddd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_label_list(labels):\n",
    "    unique_labels = set()\n",
    "    for label in labels:\n",
    "        unique_labels = unique_labels | set(label)\n",
    "    label_list = list(unique_labels)\n",
    "    label_list.sort()\n",
    "    # label_list = list(str(x) for x in range(4))\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4ce6675-987e-463d-98f7-56267763f9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3']\n",
      "{'0': 0, '1': 1, '2': 2, '3': 3}\n"
     ]
    }
   ],
   "source": [
    "label_column_name = 'ner_tags'\n",
    "\n",
    "if isinstance(features[label_column_name].feature, ClassLabel):\n",
    "    label_list = features[label_column_name].feature.names\n",
    "    # No need to convert the labels since they are already ints.\n",
    "    label_to_id = {i: i for i in range(len(label_list))}\n",
    "else:\n",
    "    label_list = get_label_list(my_datasets[\"validation\"][label_column_name])\n",
    "    label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "    \n",
    "print(label_list)\n",
    "print(label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62ed45-ab54-44c2-ac31-9547df18d260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75df2087-a7e6-41fb-b8ba-8c4b1ec5dcca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize all texts and align the labels with them.\n",
    "def tokenize_and_align_labels(examples):\n",
    "    if type(examples['tokens'][0]) is bytes:\n",
    "        print(\"Hello\")\n",
    "        examples[\"tokens\"] = [ast.literal_eval(x.decode()) for x in examples['tokens']] # examples['tokens'].map(lambda x:ast.literal_eval(x.decode()))\n",
    "        \n",
    "#     print(type(examples['tokens']))\n",
    "#     print(type(examples['tokens'][0]))\n",
    "#     print(examples['tokens'][0])\n",
    "    \n",
    "    tokenized_inputs = test_uploaded_tokenizer(\n",
    "        examples['tokens'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        # We use this argument because the texts in our dataset are lists\n",
    "        # of words (with a label for each word).\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ner_tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label\n",
    "            # to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_to_id[label[word_idx]])\n",
    "            # For the other tokens in a word, we set the label\n",
    "            # to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(\n",
    "                    label_to_id[label[word_idx]]\n",
    "                    # if data_args.label_all_tokens\n",
    "                    if False\n",
    "                    else -100\n",
    "                )\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b308a268-b628-4704-82b2-680d5b65ad1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550bb339122c41cfa8d2301945fd5709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = my_datasets[\"test\"]\n",
    "\n",
    "# Just for the purpose of testing, restricting the number of rows to be tested\n",
    "test_dataset = test_dataset.select(range(500))\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    num_proc=16,\n",
    "    # load_from_cache_file=not data_args.overwrite_cache,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6354520-8b84-4ec8-8554-8f6c2a781d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1651acd7688f477087d2720d11514518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ner_tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m my_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Just for the purpose of testing, restricting the number of rows to be tested\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# test_dataset = test_dataset.select(range(500))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenize_and_align_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# load_from_cache_file=not data_args.overwrite_cache,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/datasets/arrow_dataset.py:592\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 592\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3097\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3091\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m   3092\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3093\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3094\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3095\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3096\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3097\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3098\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3099\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3474\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3470\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3472\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3473\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3474\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3478\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3479\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3480\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3483\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3353\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3352\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3353\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3355\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3356\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3357\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[47], line 21\u001b[0m, in \u001b[0;36mtokenize_and_align_labels\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     11\u001b[0m tokenized_inputs \u001b[38;5;241m=\u001b[39m test_uploaded_tokenizer(\n\u001b[1;32m     12\u001b[0m     examples[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     13\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mner_tags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[1;32m     22\u001b[0m     word_ids \u001b[38;5;241m=\u001b[39m tokenized_inputs\u001b[38;5;241m.\u001b[39mword_ids(batch_index\u001b[38;5;241m=\u001b[39mi)\n\u001b[1;32m     23\u001b[0m     previous_word_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/datasets/formatting/formatting.py:270\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 270\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[1;32m    272\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ner_tags'"
     ]
    }
   ],
   "source": [
    "test_dataset = my_datasets[\"test\"]\n",
    "\n",
    "# Just for the purpose of testing, restricting the number of rows to be tested\n",
    "# test_dataset = test_dataset.select(range(500))\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    num_proc=16,\n",
    "    # load_from_cache_file=not data_args.overwrite_cache,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce67a7-a609-4569-abc9-1e3f8fe120b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4706b-09ca-4564-9c4b-649e23a731bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c5fb9-6d2a-4da4-ab69-79c5cd7a248d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "imported_tokenizer = RobertaTokenizerFast.from_pretrained(\n",
    "        'FacebookAI/roberta-base',\n",
    "        use_fast=True,\n",
    "        revision=\"main\",\n",
    "        use_auth_token=None,\n",
    "        add_prefix_space=True,\n",
    "    )\n",
    "imported_tokenizer.pad_token = imported_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f4ef3f5-6a0d-4cbb-a546-f802778a6823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12313</td>\n",
       "      <td>[Phylogenetic, networks, are, a, generalizatio...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12313</td>\n",
       "      <td>[This, raises, the, question, of, whether, lev...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12313</td>\n",
       "      <td>[x, in, N, ,, or, •, S, is, an, arc, side, of,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12313</td>\n",
       "      <td>[The, pseudo, code, is, in, Algorithm, 1, ., W...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12313</td>\n",
       "      <td>[First, let, (, x, ,, y, ), be, an, arc, of, Ω...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             tokens  \\\n",
       "0  12313  [Phylogenetic, networks, are, a, generalizatio...   \n",
       "1  12313  [This, raises, the, question, of, whether, lev...   \n",
       "2  12313  [x, in, N, ,, or, •, S, is, an, arc, side, of,...   \n",
       "3  12313  [The, pseudo, code, is, in, Algorithm, 1, ., W...   \n",
       "4  12313  [First, let, (, x, ,, y, ), be, an, arc, of, Ω...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d903ec28-5f1f-4245-bfee-25018567d91e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the predictions on the model that was finetuned\n",
    "predictions, labels, metrics = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e9cf6ac-b578-43b7-bdd3-4eb3e503e05f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_json_predictions_file = \"data/test_finetuned_predictions_roberta.json\"\n",
    "\n",
    "data_list = []\n",
    "for i in range(len(predictions)):\n",
    "    data_list.append(\n",
    "        {\n",
    "            \"index\": test_dataset[i][\"index\"],\n",
    "            \"predictions\": predictions[i].tolist(),\n",
    "        }\n",
    "    )\n",
    "with open(output_json_predictions_file, \"w\") as f:\n",
    "    f.write(json.dumps(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b3132673-218a-4aa8-b192-c22bfb08b244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b4673a7-153a-4ad6-9e19-7a29b1b63b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert_preds_to_original_format(\n",
    "    path_to_test_data: str = \"\",\n",
    "    path_to_test_preds: str = \"\",\n",
    "    path_to_final_output: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    This function takes the chunked preds and groups them into the original format\n",
    "    \"\"\"\n",
    "    logger.info(f\"Original Test Data Path: {path_to_test_data}\")\n",
    "    logger.info(f\"Test Set Predictions path:{path_to_test_preds}\")\n",
    "    logger.info(f\"Final Output Path:{path_to_final_output}\")\n",
    "    orig_test_data = pd.read_parquet(path_to_test_data, engine=\"fastparquet\")\n",
    "    if orig_test_data.index.name != \"index\":\n",
    "        orig_test_data.set_index(\"index\", inplace=True)\n",
    "    logger.info(f\"Original Test Data Loaded, {orig_test_data.shape}\")\n",
    "    \n",
    "    with open(path_to_test_preds, \"r\") as f:\n",
    "        test_preds = json.load(f)\n",
    "\n",
    "    test_preds_df = pd.DataFrame(test_preds).groupby(by=\"index\").agg(list)\n",
    "\n",
    "    logger.info(f\"Original Test DF = {orig_test_data.columns}, \\\n",
    "                  Index Range = {max(orig_test_data.index.tolist())}, {min(orig_test_data.index.tolist())},\\\n",
    "                  Original Test DF Shape = {orig_test_data.shape}\")\n",
    "    logger.info(f\"Predicted DF before apply = {test_preds_df.columns}\")\n",
    "    test_preds_df[\"preds\"] = test_preds_df[\"predictions\"].apply(\n",
    "        lambda x: sum(x, [])\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Predicted DF after apply Info\")\n",
    "    logger.info(f\"Predictions after DF = {test_preds_df.columns}, \\\n",
    "                  Index Range = {max(test_preds_df.index.tolist())}, {min(test_preds_df.index.tolist())},\\\n",
    "                  Original Test DF Shape = {test_preds_df.shape}\")\n",
    "\n",
    "\n",
    "    for index, row in test_preds_df.iterrows():\n",
    "        #logger.info(f\"Checking Index = {index}\")\n",
    "        #logger.info(f\"Original Length = {len(orig_test_data.loc[index, 'tokens'])}\")\n",
    "        #logger.info(f\"Predicted Length = {len(row['preds'])}\")\n",
    "        #logger.info(f\"Original Values = {orig_test_data.loc[index, 'tokens']}\")\n",
    "        #logger.info(f\"Predicted Values = {test_preds_df.at[index, 'preds']}\")\n",
    "        if len(row[\"preds\"]) > len(orig_test_data.loc[index, \"tokens\"]):\n",
    "            test_preds_df.at[index, \"preds\"] = row[\"preds\"][\n",
    "                : len(orig_test_data.loc[index, \"tokens\"])\n",
    "            ]\n",
    "\n",
    "        elif len(row[\"preds\"]) < len(orig_test_data.loc[index, \"tokens\"]):\n",
    "            test_preds_df.at[index, \"preds\"] = row[\"preds\"] + [0 for _ in range(\n",
    "                len(orig_test_data.loc[index, \"tokens\"]) - len(row[\"preds\"]))] \n",
    "    for index, row in test_preds_df.iterrows():\n",
    "        #logger.info(f\"Checking Index = {index}\")\n",
    "        assert len(row[\"preds\"]) == len(orig_test_data.loc[index, \"tokens\"])\n",
    "\n",
    "    pd.DataFrame(test_preds_df[\"preds\"]).to_parquet(path_to_final_output)\n",
    "    print(f\"final dataset saved to {path_to_final_output}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da9bad3d-e3a4-4be0-a2e7-e2010e010fab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final dataset saved to finetined_model_predictions_roberta.parquet\n"
     ]
    }
   ],
   "source": [
    "convert_preds_to_original_format('data/dev_data.parquet', output_json_predictions_file, \n",
    "                                 'data/finetined_model_predictions_roberta.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e789052-6146-408e-9e59-c131fa5d81ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1dcd06-53b1-404c-aa8b-b49e8a7b0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "output_test_predictions_file = os.path.join(\n",
    "    training_args.output_dir, \"test_predictions_roberta.txt\"\n",
    ")\n",
    "\n",
    "output_json_predictions_file = os.path.join(\n",
    "    training_args.output_dir, \"test_predictions_roberta.json\"\n",
    ")\n",
    "\n",
    "if trainer.is_world_process_zero():\n",
    "    with open(output_test_predictions_file, \"w\") as writer:\n",
    "        for prediction in true_predictions:\n",
    "            writer.write(\" \".join([str(i) for i in prediction]) + \"\\n\")\n",
    "\n",
    "    # save preds to json\n",
    "    assert len(predictions) == len(test_dataset)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358381e1-76dc-4ea1-b7c6-67f9edbfabb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for i in range(len(predictions)):\n",
    "    data_list.append(\n",
    "        {\n",
    "            \"index\": test_dataset[i][\"index\"],\n",
    "            \"predictions\": predictions[i].tolist(),\n",
    "        }\n",
    "    )\n",
    "with open(\"data/roberta_predictions_from_pretrained_test.json\", \"w\") as f:\n",
    "    f.write(json.dumps(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49e0e3-8b1d-491d-990b-8d314d1bff57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e158c5-0505-4a40-9b65-26219c49f591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce24367-eb59-47f7-a7af-9e84a96528a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TokenClassificationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1039e0be-5771-41dd-8ff2-a9e4ceedc722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roberta_pipeline = TokenClassificationPipeline('roberta_finetuned_token_classification',\n",
    "                                               model=test_uploaded_model)\n",
    "# , \n",
    "#                                               tokenizer=test_uploaded_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa8fabb-7a6f-4062-9a21-45bfd9a13bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12313</td>\n",
       "      <td>[Phylogenetic, networks, are, a, generalizatio...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12313</td>\n",
       "      <td>[This, raises, the, question, of, whether, lev...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12313</td>\n",
       "      <td>[x, in, N, ,, or, •, S, is, an, arc, side, of,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12313</td>\n",
       "      <td>[The, pseudo, code, is, in, Algorithm, 1, ., W...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12313</td>\n",
       "      <td>[First, let, (, x, ,, y, ), be, an, arc, of, Ω...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             tokens  \\\n",
       "0  12313  [Phylogenetic, networks, are, a, generalizatio...   \n",
       "1  12313  [This, raises, the, question, of, whether, lev...   \n",
       "2  12313  [x, in, N, ,, or, •, S, is, an, arc, side, of,...   \n",
       "3  12313  [The, pseudo, code, is, in, Algorithm, 1, ., W...   \n",
       "4  12313  [First, let, (, x, ,, y, ), be, an, arc, of, Ω...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_json('data/data_gen_content_dev_roberta.json')\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da82ec-76d5-4df4-8c0d-f0f08ef0ef33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(test_dataset['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf8409-abeb-4f7b-b44e-8879d685ce62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset['tokens'][0][1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcea074-e4af-4d74-89af-6bfce21bd473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(roberta_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45779001-1936-4cbf-ac78-4e6149f383b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_roberta_preds_from_finetuned \u001b[38;5;241m=\u001b[39m \u001b[43mroberta_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnetworks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_roberta_preds_from_finetuned\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:244\u001b[0m, in \u001b[0;36mTokenClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Classify each token of the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m          exists if the offsets are available within the tokenizer\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     _inputs, offset_mapping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m offset_mapping:\n\u001b[1;32m    246\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m offset_mapping\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "test_roberta_preds_from_finetuned = roberta_pipeline(['networks'])\n",
    "test_roberta_preds_from_finetuned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb20a5-52cd-4a27-9e93-9a999b0eab06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir(roberta_pipeline.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b092fe5-ca17-4361-9225-c281e9cd239e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d90f33-7816-42e8-8e1e-bcdd7c8162cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689105f-ad83-4cf3-b59e-eb603af17458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a pre-trained model\n",
    "\n",
    "model_1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ca429-e45a-49ed-aa30-7afbfd7c7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"token-classification\", model=\"TheOptimusPrimes/scibert-finetuned-dagpap24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d95be8-716c-4b00-a740-a6cff5c8e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"TheOptimusPrimes/scibert-finetuned-dagpap24\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
