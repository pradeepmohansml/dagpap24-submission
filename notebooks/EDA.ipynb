{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec8ad65-548e-4f5e-b636-7a87c3e57b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7d4c6ea-5494-45ec-a49b-837d70130e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c8b07-e738-4f81-94ed-d69c2e176335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b16050",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pq.ParquetDataset('s3://dagpapsubmission/data/data_train_data.parquet', filesystem=s3).read_pandas().to_pandas()\n",
    "dev_df = pq.ParquetDataset('s3://dagpapsubmission/data/data_dev_data.parquet', filesystem=s3).read_pandas().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec7fec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>Phylogenetic networks are a generalization of ...</td>\n",
       "      <td>b'[\"Phylogenetic\",\"networks\",\"are\",\"a\",\"genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>Prediction modelling is more closely aligned w...</td>\n",
       "      <td>b'[\"Prediction\",\"modelling\",\"is\",\"more\",\"close...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>The heat transfer exhibits the flow of heat (t...</td>\n",
       "      <td>b'[\"The\",\"heat\",\"transfer\",\"exhibits\",\"the\",\"f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>a common experience during superficial ultraso...</td>\n",
       "      <td>b'[\"a\",\"common\",\"experience\",\"during\",\"superfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22694</th>\n",
       "      <td>Code metadata Current code version v1.5.9 Perm...</td>\n",
       "      <td>b'[\"Code\",\"metadata\",\"Current\",\"code\",\"version...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "index                                                      \n",
       "12313  Phylogenetic networks are a generalization of ...   \n",
       "3172   Prediction modelling is more closely aligned w...   \n",
       "6451   The heat transfer exhibits the flow of heat (t...   \n",
       "4351   a common experience during superficial ultraso...   \n",
       "22694  Code metadata Current code version v1.5.9 Perm...   \n",
       "\n",
       "                                                  tokens  \n",
       "index                                                     \n",
       "12313  b'[\"Phylogenetic\",\"networks\",\"are\",\"a\",\"genera...  \n",
       "3172   b'[\"Prediction\",\"modelling\",\"is\",\"more\",\"close...  \n",
       "6451   b'[\"The\",\"heat\",\"transfer\",\"exhibits\",\"the\",\"f...  \n",
       "4351   b'[\"a\",\"common\",\"experience\",\"during\",\"superfi...  \n",
       "22694  b'[\"Code\",\"metadata\",\"Current\",\"code\",\"version...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e8176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7192a-c4b0-4f3a-a619-1b9d1e114f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# For running locally\n",
    "train_df = pd.read_parquet('/Users/gayatri/Downloads/train_data.parquet', engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf18e8-aa41-4617-843c-9879e18a0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ea3b8cf-3f61-47d6-abef-387eb26ba15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_df.iloc[0]['tokens']))\n",
    "print(type(train_df.iloc[0]['token_label_ids']))\n",
    "print(type(train_df.iloc[0]['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7c35d-2144-4b89-aac5-dc7fa158b354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c820e30-138e-44cf-af7b-497f8a5d3c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_label_ids</th>\n",
       "      <th>len_tokens</th>\n",
       "      <th>len_token_ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15096</th>\n",
       "      <td>Across the world, Emergency Departments are fa...</td>\n",
       "      <td>[[0, 3779, human], [3780, 7601, NLTK_synonym_r...</td>\n",
       "      <td>[Across, the, world,, Emergency, Departments, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>3821</td>\n",
       "      <td>3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14428</th>\n",
       "      <td>lung Crab is the in the lead make of cancer-re...</td>\n",
       "      <td>[[0, 4166, NLTK_synonym_replacement], [4167, 2...</td>\n",
       "      <td>[lung, Crab, is, the, in, the, lead, make, of,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>4330</td>\n",
       "      <td>4330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>The number of osteoporotic fractures, particul...</td>\n",
       "      <td>[[0, 3264, chatgpt], [3265, 17179, human], [17...</td>\n",
       "      <td>[The, number, of, osteoporotic, fractures,, pa...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>3439</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>The COVID-19 pandemic has spread to every coun...</td>\n",
       "      <td>[[0, 3666, human], [3667, 6954, chatgpt], [695...</td>\n",
       "      <td>[The, COVID-19, pandemic, has, spread, to, eve...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>3819</td>\n",
       "      <td>3819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>Endophytic fungi live a significant part of th...</td>\n",
       "      <td>[[0, 10489, human], [10490, 12000, summarized]...</td>\n",
       "      <td>[Endophytic, fungi, live, a, significant, part...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>6404</td>\n",
       "      <td>6404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "index                                                      \n",
       "15096  Across the world, Emergency Departments are fa...   \n",
       "14428  lung Crab is the in the lead make of cancer-re...   \n",
       "2144   The number of osteoporotic fractures, particul...   \n",
       "5826   The COVID-19 pandemic has spread to every coun...   \n",
       "1452   Endophytic fungi live a significant part of th...   \n",
       "\n",
       "                                             annotations  \\\n",
       "index                                                      \n",
       "15096  [[0, 3779, human], [3780, 7601, NLTK_synonym_r...   \n",
       "14428  [[0, 4166, NLTK_synonym_replacement], [4167, 2...   \n",
       "2144   [[0, 3264, chatgpt], [3265, 17179, human], [17...   \n",
       "5826   [[0, 3666, human], [3667, 6954, chatgpt], [695...   \n",
       "1452   [[0, 10489, human], [10490, 12000, summarized]...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "index                                                      \n",
       "15096  [Across, the, world,, Emergency, Departments, ...   \n",
       "14428  [lung, Crab, is, the, in, the, lead, make, of,...   \n",
       "2144   [The, number, of, osteoporotic, fractures,, pa...   \n",
       "5826   [The, COVID-19, pandemic, has, spread, to, eve...   \n",
       "1452   [Endophytic, fungi, live, a, significant, part...   \n",
       "\n",
       "                                         token_label_ids  len_tokens  \\\n",
       "index                                                                  \n",
       "15096  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        3821   \n",
       "14428  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...        4330   \n",
       "2144   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...        3439   \n",
       "5826   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        3819   \n",
       "1452   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        6404   \n",
       "\n",
       "       len_token_ids  \n",
       "index                 \n",
       "15096           3821  \n",
       "14428           4330  \n",
       "2144            3439  \n",
       "5826            3819  \n",
       "1452            6404  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify if len(tokens) == len(token_label_ids) in each row\n",
    "train_df['len_tokens'] = train_df['tokens'].map(len)\n",
    "train_df['len_token_ids'] = train_df['token_label_ids'].map(len)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d52b33d-5825-4d32-b51c-c8ab3d416124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_label_ids</th>\n",
       "      <th>len_tokens</th>\n",
       "      <th>len_token_ids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, annotations, tokens, token_label_ids, len_tokens, len_token_ids]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['len_tokens'] != train_df['len_token_ids']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8269c-a2da-4b34-b59b-788a47fabe4b",
   "metadata": {},
   "source": [
    "#### Verified that len(tokens) = len(token_label_ids) in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e2d51e-0258-4c38-8877-abe727030f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44ac12a4-a8c1-4f4c-8b57-0073e0799fb1",
   "metadata": {},
   "source": [
    "#### Splitting each row of data into multiple rows based on the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9be3d30b-939d-4bc7-a7fd-a7336f477c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_rows_on_annotation(input_df):\n",
    "    transformed_rows = []\n",
    "    for index, row in input_df.iterrows():\n",
    "        # print(index)\n",
    "        len_token = len(row['tokens'])\n",
    "        for new_annot in row['annotations']:\n",
    "            row_dict = {}\n",
    "            row_dict['doc_id'] = index\n",
    "            # row_dict['doc_text'] = row['text']\n",
    "            row_dict['tokens'] = row['tokens'][new_annot[0]:new_annot[1]]\n",
    "            row_dict['token_label_ids'] = row['token_label_ids'][new_annot[0]:new_annot[1]]\n",
    "            row_dict['annotation'] = new_annot[2]\n",
    "            row_dict['start_id'] = new_annot[0]\n",
    "            row_dict['end_id'] = new_annot[1]\n",
    "            row_dict['token_length'] = len(row_dict['tokens'])\n",
    "            if row_dict['token_length'] == 0:\n",
    "                row_dict['tokens'] = None\n",
    "            row_dict['token_label_id_length'] = len(row_dict['token_label_ids'])\n",
    "            if row_dict['token_label_id_length'] == 0:\n",
    "                row_dict['token_label_ids'] = None\n",
    "            \n",
    "            row_dict['exp_token_length'] = new_annot[1] - new_annot[0]\n",
    "            row_dict['doc_token_length'] = len_token\n",
    "            \n",
    "            if row_dict['tokens'] is not None:\n",
    "                unique_ids = set(row_dict['token_label_ids'])\n",
    "                row_dict['len_unique_token_ids'] = len(unique_ids)\n",
    "                if row_dict['len_unique_token_ids'] == 1:\n",
    "                    row_dict['unique_token_id'] = unique_ids.pop()\n",
    "                else:\n",
    "                    row_dict['unique_token_id'] = unique_ids\n",
    "            else:\n",
    "                row_dict['unique_token_id'] = None\n",
    "                row_dict['len_unique_token_ids'] = 0\n",
    "\n",
    "            if row_dict['annotation'] == \"human\":\n",
    "                row_dict['expected_token_label_id'] = 0\n",
    "            elif row_dict['annotation'] == \"NLTK_synonym_replacement\":\n",
    "                row_dict['expected_token_label_id'] = 1\n",
    "            elif row_dict['annotation'] == \"chatgpt\":\n",
    "                row_dict['expected_token_label_id'] = 2\n",
    "            elif row_dict['annotation'] == \"summarized\":\n",
    "                row_dict['expected_token_label_id'] = 3\n",
    "            else:\n",
    "                row_dict['expected_token_label_id'] = None                \n",
    "                 \n",
    "            transformed_rows.append(row_dict)\n",
    "            \n",
    "    return pd.DataFrame(transformed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af128c7-d89c-4c38-9512-6f0c73387ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "985ef8e4-fd43-4d35-b0f5-f5d5ad082f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_checks(transformed_df):\n",
    "    print(\"Total rows in the df\", transformed_df.shape)\n",
    "    print()\n",
    "    # Find the number of Nulls\n",
    "    print(\"Null check\")\n",
    "    display(transformed_df.isna().sum().reset_index().rename(columns={'index':'column_names', 0:'null_count'}))\n",
    "    print()\n",
    "    \n",
    "    # Number of rows with token_length != token_label_id_length\n",
    "    print(\"Mismatches where tokens and token_label_ids in input file do not have the same size\")\n",
    "    display(transformed_df[transformed_df['token_length'] != transformed_df['token_label_id_length']])\n",
    "    print()\n",
    "    \n",
    "    # Find the number of rows with len_unique_token_ids > 1\n",
    "    print(\"Number of rows with more than one unique token id\", transformed_df[transformed_df['len_unique_token_ids'] > 1].shape[0])\n",
    "    print()\n",
    "    print(\"Number of rows with only one unique token id\", transformed_df[transformed_df['len_unique_token_ids'] == 1].shape[0])\n",
    "    \n",
    "    # Number of rows with unique_token_id != expected_token_label_id\n",
    "    print(\"Rows with only one unique token id but the token id does not match with the expected token label id\")\n",
    "    display(transformed_df[(transformed_df['len_unique_token_ids'] == 1) & \n",
    "            (transformed_df['unique_token_id'] != transformed_df['expected_token_label_id'])])\n",
    "    print()\n",
    "\n",
    "    # Label distribution for the data with unique labels\n",
    "    print(\"Label distribution for the data with unique labels\")\n",
    "    display(transformed_df[transformed_df['len_unique_token_ids'] == 1][['annotation', 'expected_token_label_id']].value_counts().reset_index())\n",
    "    print()\n",
    "    \n",
    "    # Label distribution for all data\n",
    "    print(\"Label distribution for all the data\")\n",
    "    display(transformed_df[['annotation', 'expected_token_label_id']].value_counts().reset_index())\n",
    "    print()\n",
    "\n",
    "    print(\"Token id distribution for unique labels\")\n",
    "    display(transformed_df[transformed_df['len_unique_token_ids'] == 1][['annotation', 'unique_token_id']].value_counts().reset_index())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25da05b-5c55-493f-bd34-6d15ea7c162e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcf6e88b-938e-4793-8314-96ef29bc6b67",
   "metadata": {},
   "source": [
    "### Main eda/ pipeline\n",
    "\n",
    "1. Read the train data file\n",
    "2. Transform the data\n",
    "3. Perform sanity checks\n",
    "4. Save the file locally for further feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "189acbc4-f836-4b7c-9515-c03c7f82641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26414, 13)\n",
      "CPU times: user 907 ms, sys: 1.19 s, total: 2.1 s\n",
      "Wall time: 5.49 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_label_ids</th>\n",
       "      <th>annotation</th>\n",
       "      <th>start_id</th>\n",
       "      <th>end_id</th>\n",
       "      <th>token_length</th>\n",
       "      <th>token_label_id_length</th>\n",
       "      <th>exp_token_length</th>\n",
       "      <th>doc_token_length</th>\n",
       "      <th>len_unique_token_ids</th>\n",
       "      <th>unique_token_id</th>\n",
       "      <th>expected_token_label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15096</td>\n",
       "      <td>[Across, the, world,, Emergency, Departments, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>3779</td>\n",
       "      <td>3779</td>\n",
       "      <td>3779</td>\n",
       "      <td>3779</td>\n",
       "      <td>3821</td>\n",
       "      <td>3</td>\n",
       "      <td>{0, 1, 3}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15096</td>\n",
       "      <td>[Resources,, Project, administration,, Supervi...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NLTK_synonym_replacement</td>\n",
       "      <td>3780</td>\n",
       "      <td>7601</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>3821</td>\n",
       "      <td>3821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15096</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>summarized</td>\n",
       "      <td>7602</td>\n",
       "      <td>9401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1799</td>\n",
       "      <td>3821</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15096</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>human</td>\n",
       "      <td>9402</td>\n",
       "      <td>25014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15612</td>\n",
       "      <td>3821</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14428</td>\n",
       "      <td>[lung, Crab, is, the, in, the, lead, make, of,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>NLTK_synonym_replacement</td>\n",
       "      <td>0</td>\n",
       "      <td>4166</td>\n",
       "      <td>4166</td>\n",
       "      <td>4166</td>\n",
       "      <td>4166</td>\n",
       "      <td>4330</td>\n",
       "      <td>2</td>\n",
       "      <td>{0, 1}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                             tokens  \\\n",
       "0   15096  [Across, the, world,, Emergency, Departments, ...   \n",
       "1   15096  [Resources,, Project, administration,, Supervi...   \n",
       "2   15096                                               None   \n",
       "3   15096                                               None   \n",
       "4   14428  [lung, Crab, is, the, in, the, lead, make, of,...   \n",
       "\n",
       "                                     token_label_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                 annotation  start_id  end_id  token_length  \\\n",
       "0                     human         0    3779          3779   \n",
       "1  NLTK_synonym_replacement      3780    7601            41   \n",
       "2                summarized      7602    9401             0   \n",
       "3                     human      9402   25014             0   \n",
       "4  NLTK_synonym_replacement         0    4166          4166   \n",
       "\n",
       "   token_label_id_length  exp_token_length  doc_token_length  \\\n",
       "0                   3779              3779              3821   \n",
       "1                     41              3821              3821   \n",
       "2                      0              1799              3821   \n",
       "3                      0             15612              3821   \n",
       "4                   4166              4166              4330   \n",
       "\n",
       "   len_unique_token_ids unique_token_id  expected_token_label_id  \n",
       "0                     3       {0, 1, 3}                        0  \n",
       "1                     1               0                        1  \n",
       "2                     0            None                        3  \n",
       "3                     0            None                        0  \n",
       "4                     2          {0, 1}                        1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Read the train data file\n",
    "\n",
    "# Transform the data\n",
    "transformed_train_df = split_text_rows_on_annotation(train_df)\n",
    "print(transformed_train_df.shape)\n",
    "transformed_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd27c533-9e51-4d35-a7e5-c2143e10c0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the df (26414, 13)\n",
      "\n",
      "Null check\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_names</th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_id</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tokens</td>\n",
       "      <td>18630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>token_label_ids</td>\n",
       "      <td>18630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>start_id</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>end_id</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>token_length</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>token_label_id_length</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>exp_token_length</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>doc_token_length</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>len_unique_token_ids</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unique_token_id</td>\n",
       "      <td>18630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>expected_token_label_id</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               column_names  null_count\n",
       "0                    doc_id           0\n",
       "1                    tokens       18630\n",
       "2           token_label_ids       18630\n",
       "3                annotation           0\n",
       "4                  start_id           0\n",
       "5                    end_id           0\n",
       "6              token_length           0\n",
       "7     token_label_id_length           0\n",
       "8          exp_token_length           0\n",
       "9          doc_token_length           0\n",
       "10     len_unique_token_ids           0\n",
       "11          unique_token_id       18630\n",
       "12  expected_token_label_id           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mismatches where tokens and token_label_ids in input file do not have the same size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_label_ids</th>\n",
       "      <th>annotation</th>\n",
       "      <th>start_id</th>\n",
       "      <th>end_id</th>\n",
       "      <th>token_length</th>\n",
       "      <th>token_label_id_length</th>\n",
       "      <th>exp_token_length</th>\n",
       "      <th>doc_token_length</th>\n",
       "      <th>len_unique_token_ids</th>\n",
       "      <th>unique_token_id</th>\n",
       "      <th>expected_token_label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc_id, tokens, token_label_ids, annotation, start_id, end_id, token_length, token_label_id_length, exp_token_length, doc_token_length, len_unique_token_ids, unique_token_id, expected_token_label_id]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows with more than one unique token id 6588\n",
      "\n",
      "Number of rows with only one unique token id 1196\n",
      "Rows with only one unique token id but the token id does not match with the expected token label id\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_label_ids</th>\n",
       "      <th>annotation</th>\n",
       "      <th>start_id</th>\n",
       "      <th>end_id</th>\n",
       "      <th>token_length</th>\n",
       "      <th>token_label_id_length</th>\n",
       "      <th>exp_token_length</th>\n",
       "      <th>doc_token_length</th>\n",
       "      <th>len_unique_token_ids</th>\n",
       "      <th>unique_token_id</th>\n",
       "      <th>expected_token_label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15096</td>\n",
       "      <td>[Resources,, Project, administration,, Supervi...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NLTK_synonym_replacement</td>\n",
       "      <td>3780</td>\n",
       "      <td>7601</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>3821</td>\n",
       "      <td>3821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2144</td>\n",
       "      <td>[and, PKM, are, receiver, of, a, Ministry, of,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>human</td>\n",
       "      <td>3265</td>\n",
       "      <td>17179</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>13914</td>\n",
       "      <td>3439</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5826</td>\n",
       "      <td>[and, thus, combat, vaccine, hesitancy,, parti...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>3667</td>\n",
       "      <td>6954</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>3287</td>\n",
       "      <td>3819</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>24410</td>\n",
       "      <td>[last, two, years,, we, have, been, .»»»., ., ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>human</td>\n",
       "      <td>6331</td>\n",
       "      <td>19986</td>\n",
       "      <td>630</td>\n",
       "      <td>630</td>\n",
       "      <td>13655</td>\n",
       "      <td>6961</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>8525</td>\n",
       "      <td>[temporal, envelope, vectors, of, the, target,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>summarized</td>\n",
       "      <td>2692</td>\n",
       "      <td>4557</td>\n",
       "      <td>1865</td>\n",
       "      <td>1865</td>\n",
       "      <td>1865</td>\n",
       "      <td>9056</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26363</th>\n",
       "      <td>14116</td>\n",
       "      <td>[Mo, were, enriched, in, the, austenite, grain...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>summarized</td>\n",
       "      <td>2870</td>\n",
       "      <td>4148</td>\n",
       "      <td>1278</td>\n",
       "      <td>1278</td>\n",
       "      <td>1278</td>\n",
       "      <td>5916</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26364</th>\n",
       "      <td>14116</td>\n",
       "      <td>[and, ultimate, tensile, strength, of, 996, MP...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>4149</td>\n",
       "      <td>6123</td>\n",
       "      <td>1767</td>\n",
       "      <td>1767</td>\n",
       "      <td>1974</td>\n",
       "      <td>5916</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26369</th>\n",
       "      <td>22258</td>\n",
       "      <td>[in, 1, H,, 15, N, amide, shifts, less, than, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>NLTK_synonym_replacement</td>\n",
       "      <td>2816</td>\n",
       "      <td>6546</td>\n",
       "      <td>3730</td>\n",
       "      <td>3730</td>\n",
       "      <td>3730</td>\n",
       "      <td>7784</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26395</th>\n",
       "      <td>13123</td>\n",
       "      <td>[from, soybean, (, Fig., 2, )., This, is, expl...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>summarized</td>\n",
       "      <td>2824</td>\n",
       "      <td>4013</td>\n",
       "      <td>1189</td>\n",
       "      <td>1189</td>\n",
       "      <td>1189</td>\n",
       "      <td>7300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26403</th>\n",
       "      <td>19648</td>\n",
       "      <td>[(4), S, =, {, q, 0, }, and, Φ, current, =, ∅,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>5518</td>\n",
       "      <td>8353</td>\n",
       "      <td>2835</td>\n",
       "      <td>2835</td>\n",
       "      <td>2835</td>\n",
       "      <td>9314</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id                                             tokens  \\\n",
       "1       15096  [Resources,, Project, administration,, Supervi...   \n",
       "7        2144  [and, PKM, are, receiver, of, a, Ministry, of,...   \n",
       "10       5826  [and, thus, combat, vaccine, hesitancy,, parti...   \n",
       "82      24410  [last, two, years,, we, have, been, .»»»., ., ...   \n",
       "89       8525  [temporal, envelope, vectors, of, the, target,...   \n",
       "...       ...                                                ...   \n",
       "26363   14116  [Mo, were, enriched, in, the, austenite, grain...   \n",
       "26364   14116  [and, ultimate, tensile, strength, of, 996, MP...   \n",
       "26369   22258  [in, 1, H,, 15, N, amide, shifts, less, than, ...   \n",
       "26395   13123  [from, soybean, (, Fig., 2, )., This, is, expl...   \n",
       "26403   19648  [(4), S, =, {, q, 0, }, and, Φ, current, =, ∅,...   \n",
       "\n",
       "                                         token_label_ids  \\\n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "10     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "82     [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "89     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "26363  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "26364  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "26369  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "26395  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "26403  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                     annotation  start_id  end_id  token_length  \\\n",
       "1      NLTK_synonym_replacement      3780    7601            41   \n",
       "7                         human      3265   17179           174   \n",
       "10                      chatgpt      3667    6954           152   \n",
       "82                        human      6331   19986           630   \n",
       "89                   summarized      2692    4557          1865   \n",
       "...                         ...       ...     ...           ...   \n",
       "26363                summarized      2870    4148          1278   \n",
       "26364                   chatgpt      4149    6123          1767   \n",
       "26369  NLTK_synonym_replacement      2816    6546          3730   \n",
       "26395                summarized      2824    4013          1189   \n",
       "26403                   chatgpt      5518    8353          2835   \n",
       "\n",
       "       token_label_id_length  exp_token_length  doc_token_length  \\\n",
       "1                         41              3821              3821   \n",
       "7                        174             13914              3439   \n",
       "10                       152              3287              3819   \n",
       "82                       630             13655              6961   \n",
       "89                      1865              1865              9056   \n",
       "...                      ...               ...               ...   \n",
       "26363                   1278              1278              5916   \n",
       "26364                   1767              1974              5916   \n",
       "26369                   3730              3730              7784   \n",
       "26395                   1189              1189              7300   \n",
       "26403                   2835              2835              9314   \n",
       "\n",
       "       len_unique_token_ids unique_token_id  expected_token_label_id  \n",
       "1                         1               0                        1  \n",
       "7                         1               1                        0  \n",
       "10                        1               0                        2  \n",
       "82                        1               3                        0  \n",
       "89                        1               0                        3  \n",
       "...                     ...             ...                      ...  \n",
       "26363                     1               0                        3  \n",
       "26364                     1               0                        2  \n",
       "26369                     1               0                        1  \n",
       "26395                     1               0                        3  \n",
       "26403                     1               0                        2  \n",
       "\n",
       "[543 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution for the data with unique labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>expected_token_label_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summarized</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatgpt</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLTK_synonym_replacement</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 annotation  expected_token_label_id  count\n",
       "0                     human                        0    663\n",
       "1                summarized                        3    192\n",
       "2                   chatgpt                        2    191\n",
       "3  NLTK_synonym_replacement                        1    150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution for all the data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>expected_token_label_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>13346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatgpt</td>\n",
       "      <td>2</td>\n",
       "      <td>4447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summarized</td>\n",
       "      <td>3</td>\n",
       "      <td>4376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLTK_synonym_replacement</td>\n",
       "      <td>1</td>\n",
       "      <td>4245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 annotation  expected_token_label_id  count\n",
       "0                     human                        0  13346\n",
       "1                   chatgpt                        2   4447\n",
       "2                summarized                        3   4376\n",
       "3  NLTK_synonym_replacement                        1   4245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token id distribution for unique labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>unique_token_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatgpt</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summarized</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLTK_synonym_replacement</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chatgpt</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>human</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NLTK_synonym_replacement</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NLTK_synonym_replacement</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>human</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>summarized</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>summarized</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chatgpt</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>summarized</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation  unique_token_id  count\n",
       "0                      human                0    645\n",
       "1                    chatgpt                0    184\n",
       "2                 summarized                0    184\n",
       "3   NLTK_synonym_replacement                0    142\n",
       "4                      human                1      9\n",
       "5                    chatgpt                1      5\n",
       "6                      human                2      5\n",
       "7   NLTK_synonym_replacement                1      4\n",
       "8   NLTK_synonym_replacement                3      4\n",
       "9                      human                3      4\n",
       "10                summarized                1      3\n",
       "11                summarized                2      3\n",
       "12                   chatgpt                2      2\n",
       "13                summarized                3      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform sanity checks\n",
    "sanity_checks(transformed_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6226c6-4d9b-4210-b2cd-d39e64e95c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3cdf3104-0ed4-4523-a4e9-02184e1f891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save the file locally for further feature transformation\n",
    "transformed_train_df.to_csv('../data/tranformed_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c899e-c120-46de-8051-8795f4967f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6773e36-9bec-4c34-b4e0-cbe1f231c40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32b277-70ac-4000-a218-597af0df7b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu121.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
